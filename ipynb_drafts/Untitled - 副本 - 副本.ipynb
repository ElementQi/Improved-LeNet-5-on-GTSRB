{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-28T19:05:08.422014Z",
     "start_time": "2021-11-28T19:05:08.080307Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-28T19:05:10.105182Z",
     "start_time": "2021-11-28T19:05:08.422984Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# The German Traffic Sign Recognition Benchmark\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import csv\n",
    "\n",
    "# function for reading the images\n",
    "# arguments: path to the traffic sign data, for example './GTSRB/Training'\n",
    "# returns: list of images, list of corresponding labels \n",
    "# grayscale type image can not be shown by plt.imshow function\n",
    "# image array: for int: [0..255], for float: [0..1]\n",
    "def readTrafficSigns(rootpath, img_size=(28,28), grayscale=True):\n",
    "    '''Reads traffic sign data for German Traffic Sign Recognition Benchmark.\n",
    "    \n",
    "    Loads an image from file, resize to img_size and return as numpy array.\n",
    "    Values are normalized to range [0,1].\n",
    "    :param img: image path\n",
    "    :param img_size: image size as tuple (width, height)\n",
    "    :return: ndarray (width, height, 3) or (width, height)\n",
    "    \n",
    "    Arguments: path to the traffic sign data, for example './GTSRB/Training'\n",
    "    Returns:   list of images, list of corresponding labels\n",
    "    '''\n",
    "    \n",
    "    images = [] # images\n",
    "    labels = [] # corresponding labels\n",
    "    # loop over all 42 classes\n",
    "    for c in range(0,43):\n",
    "        prefix = rootpath + '/' + format(c, '05d') + '/' # subdirectory for class\n",
    "        gtFile = open(prefix + 'GT-'+ format(c, '05d') + '.csv') # annotations file\n",
    "        gtReader = csv.reader(gtFile, delimiter=';') # csv parser for annotations file\n",
    "        next(gtReader) # skip header\n",
    "        # loop over all images in current annotations file\n",
    "        for row in gtReader:\n",
    "            img = prefix + row[0]\n",
    "            if grayscale == True:\n",
    "                img = load_img(img, target_size=img_size, color_mode='grayscale')\n",
    "            else:\n",
    "                img = load_img(img, target_size=img_size, color_mode='rgb')\n",
    "\n",
    "            img = img_to_array(img)\n",
    "            img = img/255\n",
    "            img = img.clip(0, 1)\n",
    "            \n",
    "            images.append(img)\n",
    "            labels.append(int(row[7])) # the 8th column is the label\n",
    "        gtFile.close()\n",
    "    return np.array(images), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-28T19:05:10.112036Z",
     "start_time": "2021-11-28T19:05:10.106051Z"
    }
   },
   "outputs": [],
   "source": [
    "def readTrafficSigns_test(rootpath, img_size=(28,28), grayscale=True):\n",
    "    images = [] # images\n",
    "    labels = [] # corresponding labels\n",
    "    \n",
    "    gtFile = open(rootpath+\"/GT-final_test.csv\") # annotations file\n",
    "    gtReader = csv.reader(gtFile, delimiter=';') # csv parser for annotations file\n",
    "    next(gtReader) # skip header\n",
    "    # loop over all images in current annotations file\n",
    "    for row in gtReader:\n",
    "        img = rootpath + '/' + row[0]\n",
    "        if grayscale == True:\n",
    "            img = load_img(img, target_size=img_size, color_mode='grayscale')\n",
    "        else:\n",
    "            img = load_img(img, target_size=img_size, color_mode='rgb')\n",
    "\n",
    "        img = img_to_array(img)\n",
    "        img = img/255\n",
    "        img = img.clip(0, 1)\n",
    "\n",
    "        images.append(img)\n",
    "        labels.append(int(row[7])) # the 8th column is the label\n",
    "    gtFile.close()\n",
    "    return np.array(images), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-28T19:05:10.162899Z",
     "start_time": "2021-11-28T19:05:10.114031Z"
    }
   },
   "outputs": [],
   "source": [
    "signnames_file = 'C:/Users/ElementQi/Desktop/dataScienceProgramming/pythonProject/data/GTSRB/signnames.csv'\n",
    "with open(signnames_file) as f:\n",
    "    f.readline() # Strip the header\n",
    "    tuples = [line.strip().split(',') for line in f]\n",
    "    sign_names = {int(t[0]): t[1] for t in tuples}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-28T19:05:21.516355Z",
     "start_time": "2021-11-28T19:05:10.163896Z"
    }
   },
   "outputs": [],
   "source": [
    "train_path = 'C:/Users/ElementQi/Desktop/dataScienceProgramming/pythonProject/data/GTSRB/Final_Training/Images'\n",
    "test_path = 'C:/Users/ElementQi/Desktop/dataScienceProgramming/pythonProject/data/GTSRB/Final_Test/Images'\n",
    "\n",
    "img_size = (32,32)\n",
    "gray=True\n",
    "X_train, y_train = readTrafficSigns(train_path, img_size=img_size, grayscale=gray)\n",
    "X_test, y_test = readTrafficSigns_test(test_path, img_size=img_size, grayscale=gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-28T19:05:21.524334Z",
     "start_time": "2021-11-28T19:05:21.517352Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 39209\n",
      "Number of testing examples = 12630\n",
      "Image data shape = (32, 32, 1)\n",
      "Class number = 43\n"
     ]
    }
   ],
   "source": [
    "n_train = len(X_train)\n",
    "n_test = len(X_test)\n",
    "image_shape = X_train[0].shape\n",
    "n_classes = len(set(y_train))\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "# print(\"Number of validation examples =\", n_valid)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Class number =\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-28T19:05:21.536293Z",
     "start_time": "2021-11-28T19:05:21.527326Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "# from keras.optimizers import adadelta_v2\n",
    "from tensorflow.keras.optimizers import Adadelta\n",
    "from keras.layers import Dense,Flatten,Dropout,BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import Conv2D,MaxPooling2D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-28T19:05:21.547264Z",
     "start_time": "2021-11-28T19:05:21.538289Z"
    }
   },
   "outputs": [],
   "source": [
    "def ImLeNet(X_train,Y_train):\n",
    "    model=Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters=60,kernel_size=(5,5),strides=(1,1),input_shape=(32,32,1),padding='valid',kernel_initializer='uniform'))  #[None,28,28,5]\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    # model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Conv2D(filters=60,kernel_size=(5,5),strides=(1,1),padding='valid',kernel_initializer='uniform'))  #[None,28,28,5]\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    # model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "    model.add(Conv2D(filters=30,kernel_size=(3,3),strides=(1,1),padding='valid',kernel_initializer='uniform'))  #[None,28,28,5]\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    # model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Conv2D(filters=30,kernel_size=(3,3),strides=(1,1),padding='valid',kernel_initializer='uniform'))  #[None,28,28,5]\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    # model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten(data_format='channels_last'))\n",
    "    \n",
    "    model.add(Dense(500))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(43,activation='softmax'))\n",
    "    #打印参数\n",
    "    model.summary()\n",
    "    #编译模型\n",
    "    model.compile(optimizer=Adadelta(learning_rate=1),loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-28T19:44:54.007419Z",
     "start_time": "2021-11-28T19:05:21.548261Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 60)        1560      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 28, 28, 60)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 60)        90060     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 24, 24, 60)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 60)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 30)        16230     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 10, 10, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 30)          8130      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 8, 8, 30)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 30)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 4, 30)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 480)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               240500    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 43)                21543     \n",
      "=================================================================\n",
      "Total params: 378,023\n",
      "Trainable params: 378,023\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 39209 samples, validate on 12630 samples\n",
      "Epoch 1/30\n",
      "39209/39209 [==============================] - 11s 281us/step - loss: 1.0763 - accuracy: 0.7008 - val_loss: 0.2618 - val_accuracy: 0.9308\n",
      "Epoch 2/30\n",
      "39209/39209 [==============================] - 9s 236us/step - loss: 0.2130 - accuracy: 0.9375 - val_loss: 0.2150 - val_accuracy: 0.9489\n",
      "Epoch 3/30\n",
      "39209/39209 [==============================] - 9s 237us/step - loss: 0.1431 - accuracy: 0.9580 - val_loss: 0.1526 - val_accuracy: 0.9620\n",
      "Epoch 4/30\n",
      "39209/39209 [==============================] - 9s 236us/step - loss: 0.1057 - accuracy: 0.9696 - val_loss: 0.1444 - val_accuracy: 0.9603\n",
      "Epoch 5/30\n",
      "39209/39209 [==============================] - 9s 236us/step - loss: 0.0880 - accuracy: 0.9744 - val_loss: 0.1308 - val_accuracy: 0.9691\n",
      "Epoch 6/30\n",
      "39209/39209 [==============================] - 49s 1ms/step - loss: 0.0762 - accuracy: 0.9784 - val_loss: 0.1326 - val_accuracy: 0.9675\n",
      "Epoch 7/30\n",
      "39209/39209 [==============================] - 93s 2ms/step - loss: 0.0683 - accuracy: 0.9805 - val_loss: 0.1246 - val_accuracy: 0.9698\n",
      "Epoch 8/30\n",
      "39209/39209 [==============================] - 95s 2ms/step - loss: 0.0646 - accuracy: 0.9820 - val_loss: 0.1559 - val_accuracy: 0.9659\n",
      "Epoch 9/30\n",
      "39209/39209 [==============================] - 95s 2ms/step - loss: 0.0608 - accuracy: 0.9833 - val_loss: 0.1307 - val_accuracy: 0.9699\n",
      "Epoch 10/30\n",
      "39209/39209 [==============================] - 94s 2ms/step - loss: 0.0546 - accuracy: 0.9850 - val_loss: 0.1344 - val_accuracy: 0.9740\n",
      "Epoch 11/30\n",
      "39209/39209 [==============================] - 93s 2ms/step - loss: 0.0532 - accuracy: 0.9855 - val_loss: 0.1219 - val_accuracy: 0.9684\n",
      "Epoch 12/30\n",
      "39209/39209 [==============================] - 93s 2ms/step - loss: 0.0490 - accuracy: 0.9869 - val_loss: 0.1162 - val_accuracy: 0.9750\n",
      "Epoch 13/30\n",
      "39209/39209 [==============================] - 95s 2ms/step - loss: 0.0466 - accuracy: 0.9874 - val_loss: 0.1394 - val_accuracy: 0.9697\n",
      "Epoch 14/30\n",
      "39209/39209 [==============================] - 93s 2ms/step - loss: 0.0431 - accuracy: 0.9885 - val_loss: 0.1396 - val_accuracy: 0.9727\n",
      "Epoch 15/30\n",
      "39209/39209 [==============================] - 94s 2ms/step - loss: 0.0422 - accuracy: 0.9889 - val_loss: 0.1542 - val_accuracy: 0.9679\n",
      "Epoch 16/30\n",
      "39209/39209 [==============================] - 93s 2ms/step - loss: 0.0468 - accuracy: 0.9877 - val_loss: 0.1550 - val_accuracy: 0.9751\n",
      "Epoch 17/30\n",
      "39209/39209 [==============================] - 93s 2ms/step - loss: 0.0435 - accuracy: 0.9885 - val_loss: 0.1399 - val_accuracy: 0.9724\n",
      "Epoch 18/30\n",
      "39209/39209 [==============================] - 93s 2ms/step - loss: 0.0417 - accuracy: 0.9888 - val_loss: 0.1575 - val_accuracy: 0.9751\n",
      "Epoch 19/30\n",
      "39209/39209 [==============================] - 93s 2ms/step - loss: 0.0396 - accuracy: 0.9897 - val_loss: 0.1419 - val_accuracy: 0.9741\n",
      "Epoch 20/30\n",
      "39209/39209 [==============================] - 94s 2ms/step - loss: 0.0442 - accuracy: 0.9889 - val_loss: 0.2130 - val_accuracy: 0.9697\n",
      "Epoch 21/30\n",
      "39209/39209 [==============================] - 93s 2ms/step - loss: 0.0395 - accuracy: 0.9893 - val_loss: 0.1386 - val_accuracy: 0.9713\n",
      "Epoch 22/30\n",
      "39209/39209 [==============================] - 95s 2ms/step - loss: 0.0386 - accuracy: 0.9905 - val_loss: 0.1803 - val_accuracy: 0.9690\n",
      "Epoch 23/30\n",
      "39209/39209 [==============================] - 95s 2ms/step - loss: 0.0383 - accuracy: 0.9901 - val_loss: 0.1875 - val_accuracy: 0.9721\n",
      "Epoch 24/30\n",
      "39209/39209 [==============================] - 98s 2ms/step - loss: 0.0385 - accuracy: 0.9895 - val_loss: 0.1247 - val_accuracy: 0.9757\n",
      "Epoch 25/30\n",
      "39209/39209 [==============================] - 95s 2ms/step - loss: 0.0411 - accuracy: 0.9899 - val_loss: 0.1304 - val_accuracy: 0.9759\n",
      "Epoch 26/30\n",
      "39209/39209 [==============================] - 102s 3ms/step - loss: 0.0340 - accuracy: 0.9913 - val_loss: 0.1576 - val_accuracy: 0.9748\n",
      "Epoch 27/30\n",
      "39209/39209 [==============================] - 103s 3ms/step - loss: 0.0406 - accuracy: 0.9900 - val_loss: 0.1996 - val_accuracy: 0.9742\n",
      "Epoch 28/30\n",
      "39209/39209 [==============================] - 95s 2ms/step - loss: 0.0358 - accuracy: 0.9909 - val_loss: 0.2647 - val_accuracy: 0.9730\n",
      "Epoch 29/30\n",
      "39209/39209 [==============================] - 92s 2ms/step - loss: 0.0393 - accuracy: 0.9909 - val_loss: 0.1438 - val_accuracy: 0.9740\n",
      "Epoch 30/30\n",
      "39209/39209 [==============================] - 93s 2ms/step - loss: 0.0334 - accuracy: 0.9915 - val_loss: 0.1688 - val_accuracy: 0.9704\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "#模型训练\n",
    "    y_train = to_categorical(y_train, n_classes)\n",
    "    y_test = to_categorical(y_test, n_classes)\n",
    "\n",
    "    model=ImLeNet(X_train,y_train)\n",
    "    model.fit(x=X_train,y=y_train, batch_size=20,epochs=30, validation_data=(X_test,y_test),verbose=1)\n",
    "    #模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-28T19:45:00.226281Z",
     "start_time": "2021-11-28T19:44:54.011408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12630/12630 [==============================] - 6s 490us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1688371585143337, 0.9703879356384277]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=X_test,y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-28T19:45:05.195232Z",
     "start_time": "2021-11-28T19:45:00.227278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12630/12630 [==============================] - 5s 393us/step\n",
      "loss:0.1688371585143337===acc:0.9703879356384277\n"
     ]
    }
   ],
   "source": [
    "loss,acc=model.evaluate(x=X_test,y=y_test)\n",
    "print(\"loss:{}===acc:{}\".format(loss,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-28T19:45:05.200218Z",
     "start_time": "2021-11-28T19:45:05.196229Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
